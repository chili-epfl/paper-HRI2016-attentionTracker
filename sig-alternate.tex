% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\graphicspath{{figs/}}

\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Alternate {\ttlit ACM} SIG Proceedings Paper in LaTeX
Format\titlenote{(Produces the permission block, and
copyright information). For use with
SIG-ALTERNATE.CLS. Supported by ACM.}}
\subtitle{[Extended Abstract]
\titlenote{A full version of this paper is available as
\textit{Author's Guide to Preparing ACM SIG Proceedings Using
\LaTeX$2_\epsilon$\ and BibTeX} at
\texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{8} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Ben Trovato\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{1932 Wallamaloo Lane}\\
       \affaddr{Wallamaloo, New Zealand}\\
       \email{trovato@corporation.com}
% 2nd. author
\alignauthor
G.K.M. Tobin\titlenote{The secretary disavows
any knowledge of this author's actions.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{P.O. Box 1212}\\
       \affaddr{Dublin, Ohio 43017-6221}\\
       \email{webmaster@marysville-ohio.com}
% 3rd. author
\alignauthor Lars Th{\o}rv{\"a}ld\titlenote{This author is the
one who did all the really hard work.}\\
       \affaddr{The Th{\o}rv{\"a}ld Group}\\
       \affaddr{1 Th{\o}rv{\"a}ld Circle}\\
       \affaddr{Hekla, Iceland}\\
       \email{larst@affiliation.org}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor Lawrence P. Leipuner\\
       \affaddr{Brookhaven Laboratories}\\
       \affaddr{Brookhaven National Lab}\\
       \affaddr{P.O. Box 5000}\\
       \email{lleipuner@researchlabs.org}
% 5th. author
\alignauthor Sean Fogarty\\
       \affaddr{NASA Ames Research Center}\\
       \affaddr{Moffett Field}\\
       \affaddr{California 94035}\\
       \email{fogartys@amesres.org}
% 6th. author
\alignauthor Charles Palmer\\
       \affaddr{Palmer Research Laboratories}\\
       \affaddr{8600 Datapoint Drive}\\
       \affaddr{San Antonio, Texas 78229}\\
       \email{cpalmer@prl.com}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
In long term interactions between a human and a robot, it is necessary that the agent exhibits some sort of social intelligence to be able to engage the human providing the appropriate response to specific face-to-face situations. In a educational context, this feature becomes a must due to the fact that engagement plays a very important role in the learning process. Therefore, maximizing the interaction time at a high engagement level may provide learning benefits to the children. In this work, a real-time attention tracker based on the head pose estimation using an RGB camera is proposed to be able to identify faults during the interaction and eventually detect low engagement level situations. In this paper we want to show a practical approach to evaluate the engagement that arises from the interaction reporting several experiences in the field, with the robot Nao.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{ACM proceedings, \LaTeX, text tagging}

\section{Introduction}
The use of robots in the learning activity presents an opportunity for the children
to interact with an embodied, physical agent as part of the learning experience. Furthermore,
the use of robots in handwriting education comes with the potential to engage the child in
meta-cognition through the learning by teaching paradigm, wherein a student takes the role of
a teacher and experiences stronger educational benefits as a result (such as in \cite{Palinscar1984}).

It becomes a useful to capture the significant passive information provided by the
user during the interaction and adapt the situation to it.

The present studies has been developed in the context of the CoWriter project \footnote{The primary repository is \url{https://github.com/chili-epfl/cowriter_letter_learning}.}.

\subsection{Approach}

The first step is to estimate the head pose using the pin-hole model shown in equation \ref{eq:pinHole}. As we mention below dlib library facilitates the task by providing the 2D points \textit{m'} that composes the face silhouette. However, it is enough with obtaining eight spread points, such as right and left eyes, right and left tragions, sellion or nasal depression zone, pronasale or center of the nose, stomion or center of the mouth and menton.

Likewise, the 3D face model is needed. The proposed head pose estimation method would work best with a 3D face model of the query subject itself. When a 3D face model of the subject is not available, as in many practical situations, a 3D face model of a subject can be used. This is an estimation of the same anthropometric points \textit{M'} (for North American Caucasians) in the 3D space \cite{farkas1994anthropometry}. Moreover, the intrinsic camera parameters are necessary to be able to compose the camera matrix \textit{A}. The components are expanded in equation \ref{eq:pinHole2}.	

\begin{equation}
s  \; m' = A [R|t] M'
\label{eq:pinHole}
\end{equation}
\begin{equation}
s
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}
=
\begin{bmatrix}
f_x & 0 & c_x  \\
0 & f_y & c_y  \\
0 & 0 & 1 
\end{bmatrix}
\begin{bmatrix}
r_{11} & r_{12} & r_{13} & t_x  \\
r_{21} & r_{22} & r_{23} & t_y  \\
r_{31} & r_{32} & r_{33} & t_z  
\end{bmatrix}
\begin{bmatrix}
X \\
Y \\
Z \\
1
\end{bmatrix}
\label{eq:pinHole2}
\end{equation}

Finally, the matrix of extrinsic parameters [R|t] is obtained by joining the rotation matrix R (calculated from the rotation vector) and translation vector \textit{t}. The result is a matrix projection \textbf{P} which maps a point in the 3D space onto a point in the 2D image place solving the equation \ref{eq:p}.

\begin{equation}
s  \; m' = P \; M'
\label{eq:p}
\end{equation}

The second step is to use the matrix [R|t] to set the correct translation and orientation of the \textit{tf} frame which represents the face in the 3D space. In order to achieve that it is necessary first, to set the origin defined by the vector \textit{t}. Second, the matrix \textit{R} needs to be reformulated into a quaternion as shown in equation \ref{eq:quat} due to the smoothly interpolation between them.

\begin{equation}
\begin{bmatrix}
qw \\
qx \\
qy \\
qz
\end{bmatrix}
=
\begin{bmatrix}
\sqrt{1 + r_{11} + r_{22} + r_{33}} /2 \\
(r_{32} - r_{23})/( 4 \cdot qw) \\
(r_{13} - r_{31})/( 4 \cdot qw) \\
(r_{21} - r_{12})/( 4 \cdot qw)
\end{bmatrix}
\label{eq:quat}
\end{equation}
\\
However, it is necessary to consider the cases where the division is performed by 0 (in 180\degree rotation about the y-axis for instance) or when \textit{qw} becomes close to zero.

The third step is to generate a representation of the field of view which origin and orientation are the ones defined by the face detection \textit{tf} frame. 

Defining accurately the human field of view in the implementation is a must. Holmqvist in \cite{holmqvist2011eye} specifies that the visual human range is $ \pm  40\degree $ in the horizontal and $ \pm 25\degree $ in the vertical. In \cite{walker1980clinical} Spector provides a more detailed specification for each eye splitting the vertical range into $ 60\degree $ the upper region and $ 75\degree $ the lower one. Moreover, the horizontal range gets separated in $ 60\degree $ inwards (towards the nose) and $ 95\degree $ outwards. In the present implementation, the first approach explained has been chosen representing the field of view using a cone with such dimensions.

Assuming that the \textit{tf} frames representing the robotic agent, the two tablets, the experimenter and the observers are static, need to be monitored. This task consists on evaluating the intersection between the \textit{tf} frames and the field of view: If one focus of attention is within the region defined by the field of view, we assume the subject is looking at it. In order to solve such operation mathematically it is necessary to compute the transformation matrix between the coordinate frames to be able to locate the monitored frames \textit{A} in the subject's coordinate system \textit{B} (see equation \ref{eq:transform}).

\begin{equation}
v' = B(A^-1)v
\end{equation}

where \textit{v} is a point in \textit{A} that becomes v' in coordinate system \textit{B}. However, in practice there are, at least, three different \textit{tf} frames involved in the transformation (subject-camera, camera-base, base-focus). Following the transformation result, the distance of the monitored frame with respect to the x-axis face \textit{tf} frame, $ d_{x_{axis}} $, representing the subject's face can be computed as simple as in equation \ref{eq:pitagoras}. Always considering the x-axis as the one defining the face's orientation and thus field of view's main axis.

\begin{equation}
d_{x_{axis}} = \sqrt{t_y^2 + t_z^2}
\label{eq:pitagoras}
\end{equation}

It is necessary to compare the distance acquired $ d_{x_{axis}} $ with the radius of the field of view at the target \textit{tf} frame x-coordinate $ r_{fov} $ as shown in equation \ref{eq:fovtf}.

\begin{equation}
r_{fov} = tan\left(\frac{fov}{2}\right) \cdot t_x
\label{eq:fovtf}
\end{equation}

where \textit{fov} is the aperture angle of the field of view. Finally, if $ d_{x_{axis}}<r_{fov} $, the target is within the subject's field of view.

% Plot to clarify this??


\subsection{Experimental set-up}
Figure~\ref{realSetup} illustrates our general experimental setup: a
face-to-face child-robot interaction with an (autonomous) Aldebran's {\sc nao}
robot.

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{realSetup}
    \caption{\small Our experimental setup: face-to-face interaction with a {\sc
            nao} robot.  The robot writes on the tactile tablet, the child then
            corrects the robot by directly overwriting its letters on the tablet
            with a stylus. An adult (either a therapist or an experimenter,
            depending on the studies), remains next to the child to guide the work. 
            A second tablet allows to choose words and the camera captures the subject's face.}
    \label{realSetup}
\end{figure}

A tactile tablet (with a custom application) is used for both the robot and the
child to write: during a typical round, the child requests the robot to write
something (a single letter, a number or a full word), and push the tablet
towards the robot, the robot writes on the tablet by gesturing the writing (but
without actually physically touching the tablet), the child then pull back the
tablet, corrects the robot's attempt by writing him/herself on top or next to
the robot's writing (see Figure~\ref{fig:diego}), and ``send'' his/her
demonstration to the robot by pressing a small button on the tablet. The robot
``learns'' from this demonstration and tries again.

Since the child is assumed to take on the role of the teacher, we had to ensure
(s)he would be able to manage by him/herself the turn-taking and the overall
progression of the activity (moving to the next letter or word). In our design,
the turn-taking relies on the robot prompting for feedback once it is done with
its writing (simple sentences like ``What do you think?''), and pressing on a
small robot icon on the tablet once the child has finished correcting. In our
experiments, both were easy to grasp for children.

Implementing such a system raises several challenges that are discussed in detail in \cite{Hood:2015}.

An RGB camera has been used to acquire images of 640x480 pixels at 25 fps. The camera was located at 5 cm from the center of Nao's feet and its holder was tied to a wood base for stability purposes. Thus, the camera's objective was 9 cm above and $ 40\degree $ inclination with respect to the surface of the table. 
The subjects were typically located 50 cm away from the robot with the first tablet in front and the second one 30 cm to the left of the first one. In the same way, the experimenter was located around 60 cm to the left of the subject. Finally, two observers were located far away from the interaction field to manually assess the state of the interaction.

Figure \ref{drawSetup} allows us to intuitively identify several focuses of attention along the interaction such as the two tablets, the robot, the experimenter and the observers located in the diagonal.

\begin{figure}
    \centering
    \includegraphics[width=0.7\columnwidth]{drawSetup}
    \caption{\small Graphical representation of he set-up and the possible children focuses of attention in the scene, in red.}
    \label{drawSetup}
\end{figure}

\subsection{From face detection to Focus of Attention}
According to \cite{stiefelhagen2002tracking}

In our approach we use the opensource library dlib\footnote{http://dlib.net} \cite{dlib09}, to detect and extract the skeleton of the subject's face and then, use the obtained landmarkers to calculate the head pose orientation estimation. In this way we can estimate where the subject was looking at. Compared to intrusive hardware like head mounted displays or glasses but also images acquired from an RGB-D cameras for instance, this approach has a clear advantage of simplicity but also becomes accurate enough for general purposes in face-to-face interactions. In addition is able to handle different number and positions of participants in the scenario.

In this work, head orientation is used to predict a personâ€™s focus of attention in face-to-face interactions. Therefore, we assume that head pose is a reliable marker of the attention focus during a social interaction, in both cases human-human, human-robot. Since we estimate where the subject is looking at based on its head position, several important questions arise:

\begin{enumerate}
\item How much the head pose contributes to the real gaze of the subject?
\item Which percentage can we achieve during a real case scenario in terms of head pose estimation tracking?  
\item How accurate can we predict where the subject is looking at based only on the head pose estimation?
\item How can we evaluate the performance of the children based on the activity?
\end{enumerate}

% Stats from the paper
% Stats from me
% Real vs captured plot
% Real vs expected plot 

\section{Results}

\subsection{Head pose contribution to the gaze}

\begin{table}
	\centering
	\caption{Tracking precision in face-to-face scenario}
	\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
	Subject & 1 & 2 & 3 & 4 & 5 & 6 & Avg\\ \hline
	Tracked & 78\% & \% & \% & \% & \% & \% & \% \\ \hline
	\end{tabular}
\end{table}


\section{Discussion}
The results has shown that the percentage of accuracy in the tracking is not only conditioned by the subject's amount of movement, but also by the speed of the same movements: Restless children externalize greater levels of movement decreasing the tracker accuracy. Additionally, several recurrent computer vision challenges such as the lighting conditions, occlusions and the face angle with respect to the camera are factors that contribute to reduce the accuracy.

\subsection{Tables}

To set a wider table, which takes up the whole width of
the page's live area, use the environment
\textbf{table*} to enclose the table's contents and
the table caption.  As with a single-column table, this wide
table will ``float" to a location deemed more desirable.
Immediately following this sentence is the point at which
Table 2 is included in the input file; again, it is
instructive to compare the placement of the
table here with the table in the printed dvi
output of this document.


\begin{table*}
\centering
\caption{Some Typical Commands}
\begin{tabular}{|c|c|l|} \hline
Command&A Number&Comments\\ \hline
\texttt{{\char'134}alignauthor} & 100& Author alignment\\ \hline
\texttt{{\char'134}numberofauthors}& 200& Author enumeration\\ \hline
\texttt{{\char'134}table}& 300 & For tables\\ \hline
\texttt{{\char'134}table*}& 400& For wider tables\\ \hline\end{tabular}
\end{table*}
% end the environment with {table*}, NOTE not {table}!

\section{Conclusions}


%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!

%\balancecolumns % GM June 2007
\end{document}
